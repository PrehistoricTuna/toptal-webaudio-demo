<!DOCTYPE html>
<html>
    <head>
        <title>Create browser-based audio applications controlled by MIDI hardware</title>
        <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css" rel="stylesheet" />
    </head>
    <body>
        <div class="container">
            <h1>Create browser-based audio applications controlled by MIDI hardware</h1>
            <section class="intro">
                <p>
                    While the Web Audio API is increasinlgy gaining in popularity, especially amongst HTML5 game developers, the Web MIDI API is still little known amongst front-end developers. A big part of it probably has to do with its current lack of support; the Web MIDI API is currently only supported in Google Chrome, granted that you will enable a special flag for it. Browser manufacturers currently put little emphasis on this api, as it is planned to be part of ES7.<br/><br/>
                    Invented in the early 80's by several audio manufacturers, the objective was to create a simple, standard communication protocol for electronic music devices. Thirty years later, eventhough over the years other protocols such as OSC were developed, it is still the de-facto communication protocol for audio hardware manufacturers, and you will be hard-pressed to find a modern music producer that do not own at least one MIDI device in his studio.<br/><br/>
                    With the fast development and adoption of the Web Audio API, we can now start building browser-based applications that bridge the gap between the cloud and the physical world. Not only does the Web MIDI API allows us to build synthesizers and audio effects, but we can even start building browser-based DAW's (Digital Audio Workstation) similar in feature and performance to their current flash-based counterparts (Check out Audiotool, for example).<br/><br/>
                    In this tutorial, I will guide you through the basics of the Web MIDI API, and we will build a simple monosynth that you will be able to play with your favorite MIDI device. The full source code is available <a href="https://github.com/stephanepericat/toptal-webaudio-demo" target="_blank">here</a>, and you can test the <a href="http://webmididemo.herokuapp.com/" target="_blank">live demo</a> directly.
                </p>
                <h3>Pre-requisites</h3>
                <p>You will need the following to follow this tutorial:</p>
                <ul>
                    <li>The latest version of Google Chrome with the <kbd>#enable-web-midi</kbd> flag enabled</li>
                    <li>A MIDI keyboard connected to your computer</li>
                </ul>
                <p>Besides, we will be using Angular.js to bring a bit of structure to our applicaytion; therefore, basic knowledge of the framework is a pre-requisite.</p>
            </section>
            <section class="getting-started">
                <h2>Getting started</h2>
                <p>We will moduralize our application from the ground up by separating it in 3 modules:</p>
                <ul>
                    <li><b>WebMIDI:</b> handling the various MIDI devices connected to your computer</li>
                    <li><b>WebAudio:</b> providing the audio source for our synth</li>
                    <li><b>WebSynth:</b> connecting the web interface to the audio engine</li>
                </ul>
                <p>Finally, an App module will handle the user interaction with the web interface. Our application structure could look a bit like this:</p>
                <pre>
        |-app
        |--js
        |--- midi.js
        |--- audio.js
        |--- synth.js
        |--- app.js
        |- index.html
                </pre>
                <p>You should also install the following libraries to help you build up your aplication: <kbd>Angular.js</kbd>, <kbd>Boostrap</kbd> and <kbd>jQuery</kbd>. Probably the easiest way to do so is via Bower.</p>
            </section>
            <section class="WebMidi-module">
                <h2>The WebMidi module: connecting with the real world</h2>
                <p>Let's start by connecting our MIDI devices to our app. To do so, we will create a simple factory returning a single method. To connect to our MIDI devices via the Web MIDI API, we need to call the <kbd>navigator.requestMIDIAccess()</kbd> method:</p>
                <pre>
angular
    .module('WebMIDI', [])
    .factory('Devices', ['$window', function($window) {
        function _connect() {
            if($window.navigator && 'function' === typeof $window.navigator.requestMIDIAccess) {
                $window.navigator.requestMIDIAccess();
            } else {
                throw 'No Web MIDI support';
            }
        }

        return {
            connect: _connect
        };
    }]);
                </pre>
                <p>And that's pretty much it!<br/><br/>The requestMIDIAccess method returns a promise, so we can just return it directly and we will be handling the result of the promise in our app's controller:</p>
                <pre>
angular
    .module('DemoApp', ['WebMIDI'])
    .controller('AppCtrl', ['$scope', 'Devices', function($scope, devices) {
        $scope.devices = [];

        devices
            .connect()
            .then(function(access) {
                if('function' === typeof access.inputs) {
                    // deprecated
                    $scope.devices = access.inputs();
                    console.error('Update your Chrome version!');
                } else {
                    if(access.inputs && access.inputs.size > 0) {
                        var inputs = access.inputs.values(),
                            input = null;

                        // iterate through the devices
                        for (input = inputs.next(); input && !input.done; input = inputs.next()) {
                            $scope.devices.push(input.value);
                        }
                    } else {
                        console.error('No devices detected!');
                    }

                }
            })
            .catch(function(e) {
                console.error(e);
            });
    }]);
                </pre>
                <p>As mentionned, the requestMIDIAccess method returns a promise, passing an <i>access</i> Object to the then() method, with two properties: <kbd>inputs</kbd> and <kbd>outputs</kbd>.<br/><br/>In earlier versions of Chrome, these two properties were methods allowing you to retrieve an array of input and output devices directly. In the latest updates however, these properties are now objects. This makes quite a difference, since we now need to call the values() method on either the inputs or outputs object to retrieve the corresponding list of devices. This method acts as a generator function, and returns an iterator. Again, this API is meant to be part of ES7; therefore, implementing a generator-like behavior made a lot of sense, eventhough it is not as straight-forward as the original implementation.<br/>Finally, we can retrieve the amount of devices via the size property of the iterator object, and if there is at least one device, we simply iterate over the result by calling the next() method of the iterator object, and pushing each device to an array defined on the $scope. On the front-end, we can implement a simple select box which will list all the available input devices and let us choose which device we want to use as active device to control the web synth:</p>
                <pre>
&lt;select ng-model="activeDevice" class="form-control" ng-options="device.manufacturer + ' ' + device.name for device in devices"&gt;
    &lt;option value="" disabled>Choose a MIDI device...&lt;/option&gt;
&lt;/select&gt;
                </pre>
                <p>We bound this select box to a $scope variable called <kbd>activeDevice</kbd>. We will use this later to connect this active device to the synth.</p>
            </section>
            <section class="WebAudio-module">
                <h2>The WebAudio module: making noise</h2>
                <p>The WebAudio API allows us to not only play sound files, but also generate sounds by recreating the essential components of synthesizers such as oscillators, filters and gain nodes <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext#Methods" target="_blank">amongst others</a>.</p>
                <h3>Create an oscillator</h3>
                <p>The role of oscillators is to output a wave form. There are various types of wave forms, amongst which four are supported in the WebAudio API: <kbd>sine</kbd>, <kbd>square</kbd>, <kbd>triangle</kbd> and <kbd>sawtooth</kbd>. Wave forms are said to "oscillate" at a certain frequency. A certain range of frequencies are audible by human beings; they are known as sounds. Alternatively, when they are oscillating at low frequencies, oscillators can also help us build LFO's ("low frequency oscillator") so we can modulate our sounds (but this is out of the scope of this tutorial).<br/><br/>The first thing we need to do to create some sounds is to instantiate a new AudioContext:</p>
                <pre>
function _createContext() {
    self.ctx = new $window.AudioContext();
}
                </pre>
                <p>From there, we can instantiate any of the components made available by the WebAudio API. Since we might create multiple instances of each components, it makes sense to create services to be able to create new, unique instances of the components we need. Let's start by creating the service to generate a new oscillator:</p>
                <pre>
angular
    .module('WebAudio', [])
    .service('OSC', function() {
        var self;

        function Oscillator(ctx) {
            self = this;
            self.osc = ctx.createOscillator();

            return self;
        }
    });
                </pre>
                <p>We can now instantiate new oscillators at our will, passing as unique argument the AudioContext instance we created earlier. Now, we can build some wrapper methods for syntaxic sugar, and return the Oscillator function:</p>
                <pre>
Oscillator.prototype.setOscType = function(type) {
    if(type) {
        self.osc.type = type
    }
}

Oscillator.prototype.setFrequency = function(freq, time) {
    self.osc.frequency.setTargetAtTime(freq, 0, time);
};

Oscillator.prototype.start = function(pos) {
    self.osc.start(pos);
}

Oscillator.prototype.stop = function(pos) {
    self.osc.stop(pos);
}

Oscillator.prototype.connect = function(i) {
    self.osc.connect(i);
}

Oscillator.prototype.cancel = function() {
    self.osc.frequency.cancelScheduledValues(0);
}

return Oscillator;
                </pre>
            </section>
        </div>
    </body>
</html>
